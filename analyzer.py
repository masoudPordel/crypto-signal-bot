import os
os.environ["PYTHONIOENCODING"] = "utf-8"
os.environ["LC_ALL"] = "en_US.UTF-8"

import requests
import pandas as pd
import numpy as np
from scipy.signal import argrelextrema
import ccxt.async_support as ccxt
import asyncio
import time
import logging
import traceback
from datetime import datetime, timedelta
from sklearn.tree import DecisionTreeClassifier
from typing import Optional, Dict, Any, List

# ØªÙ†Ø¸ÛŒÙ… Ù„Ø§Ú¯â€ŒÙ‡Ø§
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s - [File: %(filename)s | Line: %(lineno)d | Func: %(funcName)s]',
    handlers=[
        logging.FileHandler("debug_detailed.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø«Ø§Ø¨Øª
CMC_API_KEY = os.getenv("CMC_API_KEY", "ff5a7b31-458f-4e5a-a684-acba34c33c11")
COINMARKETCAL_API_KEY = os.getenv("COINMARKETCAL_API_KEY", "iFrSo3PUBJ36P8ZnEIBMvakO5JutSIU1XJvG7ALa")
TIMEFRAMES = ["15m", "1h", "4h", "1d"]

VOLUME_WINDOW = 20
CACHE = {}
CACHE_TTL = 600
MAX_CONCURRENT_REQUESTS = 10
WAIT_BETWEEN_REQUESTS = 0.5
WAIT_BETWEEN_CHUNKS = 3

LIQUIDITY_REJECTS = 0
VOLUME_REJECTS = 0
SR_REJECTS = 0

# ØªØ§Ø¨Ø¹ Ø¯Ø±ÛŒØ§ÙØª Ø¢ÛŒØ¯ÛŒ Ú©ÙˆÛŒÙ† Ø§Ø² CMC
def get_coin_id(symbol: str) -> Optional[int]:
    url = "https://pro-api.coinmarketcap.com/v1/cryptocurrency/map"
    headers = {'Accepts': 'application/json', 'X-CMC_PRO_API_KEY': CMC_API_KEY}
    params = {'symbol': symbol}
    try:
        logging.debug(f"Ø´Ø±ÙˆØ¹ Ø¯Ø±ÛŒØ§ÙØª Ø¢ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ {symbol}")
        resp = requests.get(url, headers=headers, params=params, timeout=10)
        data = resp.json()
        if 'data' in data and len(data['data']) > 0:
            coin_id = data['data'][0]['id']
            logging.info(f"Ø¯Ø±ÛŒØ§ÙØª Ø¢ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ {symbol}: coin_id={coin_id}")
            return coin_id
        else:
            logging.warning(f"Ø¢ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} ÛŒØ§ÙØª Ù†Ø´Ø¯")
            return None
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¢ÛŒØ¯ÛŒ Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
        return None

# ØªØ§Ø¨Ø¹ Ø¯Ø±ÛŒØ§ÙØª 500 Ù†Ù…Ø§Ø¯ Ø¨Ø±ØªØ± Ø§Ø² CMC
def get_top_500_symbols_from_cmc() -> List[str]:
    url = "https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest"
    headers = {'Accepts': 'application/json', 'X-CMC_PRO_API_KEY': CMC_API_KEY}
    params = {'start': '1', 'limit': '500', 'convert': 'USD'}
    try:
        logging.debug(f"Ø´Ø±ÙˆØ¹ Ø¯Ø±ÛŒØ§ÙØª ÛµÛ°Û° Ù†Ù…Ø§Ø¯ Ø¨Ø±ØªØ± Ø§Ø² CMC")
        resp = requests.get(url, headers=headers, params=params, timeout=10)
        data = resp.json()
        logging.info(f"Ø¯Ø±ÛŒØ§ÙØª ÛµÛ°Û° Ù†Ù…Ø§Ø¯ Ø¨Ø±ØªØ± Ø§Ø² CMC: ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…Ø§Ø¯Ù‡Ø§={len(data['data'])}")
        return [entry['symbol'] for entry in data['data']]
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø§Ø² CMC: {e}")
        return []

# ØªØ§Ø¨Ø¹ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø§Ø®Øµ ØªØ±Ø³ Ùˆ Ø·Ù…Ø¹
def get_fear_and_greed_index() -> int:
    url = "https://api.alternative.me/fng/?limit=1"
    try:
        response = requests.get(url, timeout=10)
        data = response.json()
        value = int(data["data"][0]["value"])
        logging.info(f"Ø´Ø§Ø®Øµ ØªØ±Ø³ Ùˆ Ø·Ù…Ø¹ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯: {value}")
        return value
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø´Ø§Ø®Øµ ØªØ±Ø³ Ùˆ Ø·Ù…Ø¹: {e}")
        return 50

# Ú©Ù„Ø§Ø³ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§
class IndicatorCalculator:
    @staticmethod
    def compute_rsi(df: pd.DataFrame, period: int = 14) -> pd.Series:
        delta = df["close"].diff()
        gain = delta.where(delta > 0, 0).rolling(period).mean()
        loss = -delta.where(delta < 0, 0).rolling(period).mean()
        rs = gain / loss.replace(0, 1e-10)
        rsi = 100 - (100 / (1 + rs))
        return rsi

    @staticmethod
    def compute_atr(df: pd.DataFrame, period: int = 14) -> pd.Series:
        tr = pd.concat([df["high"] - df["low"], abs(df["high"] - df["close"].shift()), abs(df["low"] - df["close"].shift())], axis=1).max(axis=1)
        atr = tr.rolling(period).mean()
        return atr

    @staticmethod
    def compute_bollinger_bands(df: pd.DataFrame, period: int = 20, std_dev: float = 2) -> tuple:
        sma = df["close"].rolling(period).mean()
        std = df["close"].rolling(period).std()
        upper = sma + std_dev * std
        lower = sma - std_dev * std
        return upper, lower

    @staticmethod
    def compute_adx(df: pd.DataFrame, period: int = 14) -> pd.Series:
        df["up"] = df["high"].diff()
        df["down"] = -df["low"].diff()
        df["+DM"] = np.where((df["up"] > df["down"]) & (df["up"] > 0), df["up"], 0.0)
        df["-DM"] = np.where((df["down"] > df["up"]) & (df["down"] > 0), df["down"], 0.0)
        tr = pd.concat([df["high"] - df["low"], abs(df["high"] - df["close"].shift()), abs(df["low"] - df["close"].shift())], axis=1).max(axis=1)
        tr_smooth = tr.rolling(window=period).sum()
        plus_di = 100 * (df["+DM"].rolling(window=period).sum() / tr_smooth)
        minus_di = 100 * (df["-DM"].rolling(window=period).sum() / tr_smooth)
        dx = (abs(plus_di - minus_di) / (plus_di + minus_di)) * 100
        adx = dx.rolling(window=period).mean()
        return adx

    @staticmethod
    def compute_stochastic(df: pd.DataFrame, period: int = 14) -> pd.Series:
        low_min = df["low"].rolling(window=period).min()
        high_max = df["high"].rolling(window=period).max()
        k = 100 * (df["close"] - low_min) / (high_max - low_min).replace(0, 1e-10)
        return k

    @staticmethod
    def compute_mfi(df: pd.DataFrame, period: int = 14) -> pd.Series:
        typical_price = (df['high'] + df['low'] + df['close']) / 3
        raw_money_flow = typical_price * df['volume']
        positive_flow = raw_money_flow.where(typical_price > typical_price.shift(1), 0).rolling(period).sum()
        negative_flow = raw_money_flow.where(typical_price < typical_price.shift(1), 0).rolling(period).sum()
        mfi = 100 - (100 / (1 + positive_flow / negative_flow.replace(0, 1e-10)))
        return mfi

# Ú©Ù„Ø§Ø³ ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§
class PatternDetector:
    @staticmethod
    def detect_pin_bar(df: pd.DataFrame) -> pd.Series:
        df["body"] = abs(df["close"] - df["open"])
        df["range"] = df["high"] - df["low"]
        df["upper"] = df["high"] - df[["close", "open"]].max(axis=1)
        df["lower"] = df[["close", "open"]].min(axis=1) - df["low"]
        pin_bar = (df["body"] < 0.3 * df["range"]) & ((df["upper"] > 2 * df["body"]) | (df["lower"] > 2 * df["body"]))
        return pin_bar

    @staticmethod
    def detect_engulfing(df: pd.DataFrame) -> pd.Series:
        prev_o = df["open"].shift(1)
        prev_c = df["close"].shift(1)
        engulfing = (((df["close"] > df["open"]) & (prev_c < prev_o) & (df["close"] > prev_o) & (df["open"] < prev_c)) |
                     ((df["close"] < df["open"]) & (prev_c > prev_o) & (df["close"] < prev_o) & (df["open"] > prev_c)))
        return engulfing

    @staticmethod
    def detect_elliott_wave(df: pd.DataFrame) -> pd.DataFrame:
        df["WavePoint"] = np.nan
        highs = argrelextrema(df['close'].values, np.greater, order=5)[0]
        lows = argrelextrema(df['close'].values, np.less, order=5)[0]
        df.loc[df.index[highs], "WavePoint"] = df.loc[df.index[highs], "close"]
        df.loc[df.index[lows], "WavePoint"] = df.loc[df.index[lows], "close"]
        df["WaveTrend"] = np.nan
        df["WaveTrend"] = df["WaveTrend"].astype("object")
        wave_points = df["WavePoint"].dropna().index
        if len(wave_points) >= 5:
            recent_points = df.loc[wave_points[-5:], "close"]
            if recent_points.is_monotonic_increasing:
                df.loc[wave_points[-1], "WaveTrend"] = "Up"
            elif recent_points.is_monotonic_decreasing:
                df.loc[wave_points[-1], "WaveTrend"] = "Down"
        return df
        

    @staticmethod
    def detect_support_resistance(df: pd.DataFrame, window: int = 10) -> tuple:
        if len(df) < window:
            logging.warning(f"Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø­Ù…Ø§ÛŒØª/Ù…Ù‚Ø§ÙˆÙ…Øª: {len(df)} Ú©Ù†Ø¯Ù„")
            return None, None, []

        high = df['high'].rolling(window).max()
        low = df['low'].rolling(window).min()
        close = df['close'].rolling(window).mean()
        pivot = (high + low + close) / 3
        resistance = pivot + (high - low) * 0.382
        support = pivot - (high - low) * 0.382

        recent_highs = df['high'][(df['high'].shift(1) < df['high']) & (df['high'].shift(-1) < df['high'])].iloc[-window:]
        recent_lows = df['low'][(df['low'].shift(1) > df['low']) & (df['low'].shift(-1) > df['low'])].iloc[-window:]

        recent_resistance = recent_highs.max() if not recent_highs.empty else resistance.iloc[-1]
        recent_support = recent_lows.min() if not recent_lows.empty else support.iloc[-1]

        if pd.isna(recent_resistance) or recent_resistance == 0:
            recent_resistance = df['close'].iloc[-20:].mean() * 1.02
            logging.warning(f"Ù…Ù‚Ø§ÙˆÙ…Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ {len(df)} Ú©Ù†Ø¯Ù„ ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯: {recent_resistance}")

        if pd.isna(recent_support) or recent_support == 0:
            recent_support = df['close'].iloc[-20:].mean() * 0.98
            logging.warning(f"Ø­Ù…Ø§ÛŒØª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ {len(df)} Ú©Ù†Ø¯Ù„ ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯: {recent_support}")

        volume_profile = df['volume'].groupby(df['close'].round(2)).sum()
        vol_threshold = volume_profile.quantile(0.5)
        high_vol_levels = volume_profile[volume_profile > vol_threshold].index.tolist()

        return recent_support, recent_resistance, high_vol_levels
        
    @staticmethod
    def detect_rsi_divergence(df: pd.DataFrame, lookback: int = 10) -> tuple:
        rsi = IndicatorCalculator.compute_rsi(df)
        prices = df['close']
        recent_lows_price = argrelextrema(prices.values, np.less, order=lookback)[0]
        recent_highs_price = argrelextrema(prices.values, np.greater, order=lookback)[0]
        recent_lows_rsi = argrelextrema(rsi.values, np.less, order=lookback)[0]
        recent_highs_rsi = argrelextrema(rsi.values, np.greater, order=lookback)[0]
        bullish_divergence = False
        bearish_divergence = False
        if len(recent_lows_price) > 1 and len(recent_lows_rsi) > 1:
            last_price_low = prices.iloc[recent_lows_price[-1]]
            prev_price_low = prices.iloc[recent_lows_price[-2]]
            last_rsi_low = rsi.iloc[recent_lows_rsi[-1]]
            prev_rsi_low = rsi.iloc[recent_lows_rsi[-2]]
            bullish_divergence = (last_price_low < prev_price_low * 1.02) and (last_rsi_low > prev_rsi_low * 0.98)
        if len(recent_highs_price) > 1 and len(recent_highs_rsi) > 1:
            last_price_high = prices.iloc[recent_highs_price[-1]]
            prev_price_high = prices.iloc[recent_highs_price[-2]]
            last_rsi_high = rsi.iloc[recent_highs_rsi[-1]]
            prev_rsi_high = rsi.iloc[recent_highs_rsi[-2]]
            bearish_divergence = (last_price_high > prev_price_high * 0.98) and (last_rsi_high < prev_rsi_high * 1.02)
        return bullish_divergence, bearish_divergence

# Ú©Ù„Ø§Ø³ ÙÛŒÙ„ØªØ± Ø³ÛŒÚ¯Ù†Ø§Ù„
class SignalFilter:
    def __init__(self):
        self.model = DecisionTreeClassifier(max_depth=3)
        self.trained = False

    def train(self, X: np.ndarray, y: np.ndarray) -> None:
        if len(X) > 0 and len(y) > 0:
            self.model.fit(X, y)
            self.trained = True
            logging.info("Decision Tree Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯.")
        else:
            logging.warning("Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø¨Ø±Ø§ÛŒ Decision Tree Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª.")

    def predict(self, features: list) -> float:
        if not self.trained:
            logging.warning("Decision Tree Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù¾ÛŒØ´â€ŒÙØ±Ø¶=True")
            return 10
        try:
            prediction = self.model.predict_proba([features])[0][1]
            score = prediction * 20
            logging.debug(f"Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Decision Tree: features={features}, score={score:.2f}")
            return score
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Decision Tree: {e}, traceback={str(traceback.format_exc())}")
            return 0

# ØªØ§Ø¨Ø¹ Ø¨Ø±Ø±Ø³ÛŒ Ù†Ù‚Ø¯ÛŒÙ†Ú¯ÛŒ
async def check_liquidity(exchange: ccxt.Exchange, symbol: str, df: pd.DataFrame) -> tuple:
    global LIQUIDITY_REJECTS
    try:
        ticker = await exchange.fetch_ticker(symbol)
        bid = ticker.get('bid')
        ask = ticker.get('ask')
        if bid is None or ask is None or bid == 0 or ask == 0:
            logging.warning(f"Ø¯Ø§Ø¯Ù‡ Ù†Ù‚Ø¯ÛŒÙ†Ú¯ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª: bid={bid}, ask={ask}")
            return float('inf'), 0
        spread = (ask - bid) / ((bid + ask) / 2)
        spread_history = []
        for i in range(-5, 0):
            try:
                past_ticker = await exchange.fetch_ticker(symbol)
                past_bid = past_ticker.get('bid')
                past_ask = past_ticker.get('ask')
                if past_bid is None or past_ask is None or past_bid == 0 or past_ask == 0:
                    continue
                past_spread = (past_ask - past_bid) / ((past_bid + past_ask) / 2)
                spread_history.append(past_spread)
            except Exception as e:
                logging.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ú¯Ø°Ø´ØªÙ‡ Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
                continue
        spread_mean = np.mean(spread_history) if spread_history else 0.02
        spread_std = np.std(spread_history) if spread_history else 0.005
        spread_threshold = 0.005  # Ø¢Ø³ØªØ§Ù†Ù‡ Ø³Ø®Øªâ€ŒÚ¯ÛŒØ±Ø§Ù†Ù‡â€ŒØªØ± Ø¨Ø±Ø§ÛŒ Ù†Ù‚Ø¯ÛŒÙ†Ú¯ÛŒ
        if spread > spread_threshold:
            logging.warning(f"Ø§Ø³Ù¾Ø±Ø¯ Ø¨Ø±Ø§ÛŒ {symbol} Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ø¨Ø§Ù„Ø§Ø³Øª: spread={spread:.4f}")
            LIQUIDITY_REJECTS += 1
            return spread, -10
        score = 15 if spread < spread_threshold else -5
        logging.info(f"Ù†Ù‚Ø¯ÛŒÙ†Ú¯ÛŒ {symbol}: spread={spread:.4f}, threshold={spread_threshold:.4f}, score={score}")
        if spread >= spread_threshold:
            LIQUIDITY_REJECTS += 1
        return spread, score
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ù†Ù‚Ø¯ÛŒÙ†Ú¯ÛŒ Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
        return float('inf'), 0

# ØªØ§Ø¨Ø¹ Ø¨Ø±Ø±Ø³ÛŒ Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ÛŒ Ø¨Ø§Ø²Ø§Ø±
def check_market_events(symbol: str) -> int:
    coin_id = get_coin_id(symbol.split('/')[0])
    if not coin_id:
        return 0
    url = "https://developers.coinmarketcal.com/v1/events"
    headers = {
        "x-api-key": COINMARKETCAL_API_KEY,
        "Accept": "application/json",
        "Accept-Encoding": "deflate, gzip"
    }
    start_date = (datetime.utcnow() - timedelta(days=7)).replace(hour=0, minute=0, second=0, microsecond=0).strftime("%Y-%m-%d")
    end_date = (datetime.utcnow() + timedelta(days=7)).replace(hour=0, minute=0, second=0, microsecond=0).strftime("%Y-%m-%d")
    params = {
        "coinId": str(coin_id),
        "max": 5,
        "dateRangeStart": start_date,
        "dateRangeEnd": end_date
    }
    try:
        logging.debug(f"Ø´Ø±ÙˆØ¹ Ø¯Ø±ÛŒØ§ÙØª Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ Ø¨Ø±Ø§ÛŒ {symbol}, coin_id={coin_id}")
        time.sleep(0.5)
        resp = requests.get(url, headers=headers, params=params, timeout=10)
        events = resp.json()
        event_score = 0
        if not events or "body" not in events or not events["body"]:
            return 0
        for event in events["body"]:
            title = event.get("title", "")
            description = event.get("description", "")
            if isinstance(title, dict):
                title = title.get("en", "")
            if isinstance(description, dict):
                description = description.get("en", "")
            title = title.lower() if isinstance(title, str) else ""
            description = description.lower() if isinstance(description, str) else ""
            if "burn" in title or "token burn" in description:
                event_score += 15
            elif "listing" in title or "exchange" in description:
                event_score += 10
            elif "partnership" in title or "collaboration" in description:
                event_score += 5
            elif "hack" in title or "security breach" in description:
                event_score -= 20
            elif "lawsuit" in title or "negative" in description:
                event_score -= 15
        return event_score
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø±ÙˆÛŒØ¯Ø§Ø¯Ù‡Ø§ Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
        return 0

# ØªØ§Ø¨Ø¹ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§
def compute_indicators(df: pd.DataFrame) -> pd.DataFrame:
    try:
        df = df.ffill().bfill().fillna(0)
        df["EMA12"] = df["close"].ewm(span=12).mean()
        df["EMA26"] = df["close"].ewm(span=26).mean()
        df["MACD"] = df["EMA12"] - df["EMA26"]
        df["Signal"] = df["MACD"].ewm(span=9).mean()
        df["RSI"] = IndicatorCalculator.compute_rsi(df)
        df["ATR"] = IndicatorCalculator.compute_atr(df)
        df["ADX"] = IndicatorCalculator.compute_adx(df)
        df["Stochastic"] = IndicatorCalculator.compute_stochastic(df)
        df["BB_upper"], df["BB_lower"] = IndicatorCalculator.compute_bollinger_bands(df)
        df["PinBar"] = PatternDetector.detect_pin_bar(df)
        df["Engulfing"] = PatternDetector.detect_engulfing(df)
        df = PatternDetector.detect_elliott_wave(df)
        df["MFI"] = IndicatorCalculator.compute_mfi(df)

        # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Hammer Ùˆ Doji
        df["Hammer"] = ((df["close"] - df["low"]) / (df["high"] - df["low"]) > 0.66) & (df["close"] > df["open"])  # Hammer ØµØ¹ÙˆØ¯ÛŒ
        df["Doji"] = abs(df["close"] - df["open"]) / (df["high"] - df["low"]) < 0.1  # Doji

        logging.debug(f"Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø´Ø¯Ù†Ø¯: {list(df.columns)}")
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§: {str(e)}")
        df["EMA12"] = df["close"].mean()
        df["EMA26"] = df["close"].mean()
        df["MACD"] = 0
        df["Signal"] = 0
        df["RSI"] = 50
        df["ATR"] = 0
        df["ADX"] = 0
        df["Stochastic"] = 50
        df["BB_upper"] = df["close"].mean() * 1.1
        df["BB_lower"] = df["close"].mean() * 0.9
        df["PinBar"] = False
        df["Engulfing"] = False
        df["WavePoint"] = np.nan
        df["MFI"] = 50
        # Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ Hammer Ùˆ Doji
        df["Hammer"] = False
        df["Doji"] = False
        logging.warning(f"Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ Ø¨Ø§ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ù¾Ø± Ø´Ø¯Ù†Ø¯")
    return df

# ØªØ§Ø¨Ø¹ ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø±
async def analyze_market_structure(exchange: ccxt.Exchange, symbol: str) -> Dict[str, Any]:
    try:
        logging.info(f"Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø± Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… 4h")
        df_4h = await get_ohlcv_cached(exchange, symbol, "4h", limit=50)
        if df_4h is None or len(df_4h) < 50:
            logging.warning(f"Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø± {symbol} @ 4h: ØªØ¹Ø¯Ø§Ø¯ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§={len(df_4h) if df_4h is not None else 0}")
            return {"trend": "Neutral", "score": 0, "support": 0, "resistance": 0, "fng_index": 50}

        df_4h = compute_indicators(df_4h)
        last_4h = df_4h.iloc[-1]

        trend_score = 0
        trend_direction = "Neutral"
        if last_4h["EMA12"] > last_4h["EMA26"]:
            trend_score += 10
            trend_direction = "Up"
        elif last_4h["EMA12"] < last_4h["EMA26"]:
            trend_score += -10
            trend_direction = "Down"

        support, resistance, _ = PatternDetector.detect_support_resistance(df_4h)
        logging.info(f"Ø³Ø·ÙˆØ­ Ú©Ù„ÛŒØ¯ÛŒ Ø¯Ø± 4h Ø¨Ø±Ø§ÛŒ {symbol}: Ø­Ù…Ø§ÛŒØª={support:.2f}, Ù…Ù‚Ø§ÙˆÙ…Øª={resistance:.2f}")

        fng_index = get_fear_and_greed_index()
        if fng_index < 25:
            trend_score += 5
            logging.info(f"Ø´Ø§Ø®Øµ ØªØ±Ø³ Ùˆ Ø·Ù…Ø¹ Ø¯Ø± 4h Ø¨Ø±Ø§ÛŒ {symbol}: {fng_index} (ØªØ±Ø³ Ø´Ø¯ÛŒØ¯) - 10 Ø§Ù…ØªÛŒØ§Ø² Ø¨Ù‡ Ø±ÙˆÙ†Ø¯ ØµØ¹ÙˆØ¯ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯")
        elif fng_index > 75:
            trend_score += -5
            logging.info(f"Ø´Ø§Ø®Øµ ØªØ±Ø³ Ùˆ Ø·Ù…Ø¹ Ø¯Ø± 4h Ø¨Ø±Ø§ÛŒ {symbol}: {fng_index} (Ø·Ù…Ø¹ Ø´Ø¯ÛŒØ¯) - 10 Ø§Ù…ØªÛŒØ§Ø² Ø¨Ù‡ Ø±ÙˆÙ†Ø¯ Ù†Ø²ÙˆÙ„ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯")

        result = {
            "trend": trend_direction,
            "score": trend_score,
            "support": support,
            "resistance": resistance,
            "fng_index": fng_index
        }
        logging.info(f"ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø± Ø¨Ø±Ø§ÛŒ {symbol} @ 4h ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯: {result}")
        return result
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø± Ø¨Ø±Ø§ÛŒ {symbol} @ 4h: {str(e)}")
        return {"trend": "Neutral", "score": 0, "support": 0, "resistance": 0, "fng_index": 50}

# ØªØ§Ø¨Ø¹ Ø¯Ø±ÛŒØ§ÙØª Ù‚ÛŒÙ…Øª ÙˆØ§Ù‚Ø¹ÛŒ
async def get_live_price(exchange: ccxt.Exchange, symbol: str, max_attempts: int = 3) -> Optional[float]:
    attempt = 0
    last_ticker = None
    while attempt < max_attempts:
        try:
            ticker = await exchange.fetch_ticker(symbol)
            bid = ticker.get('bid')
            ask = ticker.get('ask')
            last = ticker.get('last')
            if bid is None or ask is None or last is None or bid <= 0 or ask <= 0:
                logging.warning(f"Ø¯Ø§Ø¯Ù‡ Ù‚ÛŒÙ…Øª ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª: bid={bid}, ask={ask}, last={last}")
                attempt += 1
                await asyncio.sleep(0.3)
                continue
            live_price = (bid + ask) / 2 if bid and ask else last
            last_ticker = live_price
            logging.info(f"Ù‚ÛŒÙ…Øª ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø§Ø²Ø§Ø± Ø¨Ø±Ø§ÛŒ {symbol}: live_price={live_price}, bid={bid}, ask={ask}, last={last}")
            return live_price
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù‚ÛŒÙ…Øª ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø± ØªÙ„Ø§Ø´ {attempt + 1}: {e}")
            attempt += 1
            await asyncio.sleep(0.3)
    try:
        df_1m = await get_ohlcv_cached(exchange, symbol, "1m")
        if df_1m is not None and len(df_1m) > 0:
            fallback_price = df_1m["close"].iloc[-1]
            logging.warning(f"Ù‚ÛŒÙ…Øª ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯ØŒ Ø§Ø² Ù‚ÛŒÙ…Øª Ú©Ù†Ø¯Ù„ 1m Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯: {fallback_price}")
            return fallback_price
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù‚ÛŒÙ…Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ {symbol}: {e}")
    logging.error(f"Ù†Ø§ØªÙˆØ§Ù†ÛŒ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù‚ÛŒÙ…Øª Ø¨Ø±Ø§ÛŒ {symbol} Ù¾Ø³ Ø§Ø² {max_attempts} ØªÙ„Ø§Ø´")
    return None

async def find_entry_point(
    exchange: ccxt.Exchange,
    symbol: str,
    signal_type: str,
    support: float,
    resistance: float,
    confirm_next_candle: bool = False,
    debug_mode: bool = True
) -> Optional[Dict]:
    def log_debug(message):
        if debug_mode:
            logging.info(message)

    def log_rejection(reason: str, details: dict = None):
        if debug_mode:
            logging.info(f"[REJECTED] {symbol} | reason={reason} | details={details or {}}")

    try:
        log_debug(f"ğŸ” Ø´Ø±ÙˆØ¹ Ø¨Ø±Ø±Ø³ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø±Ø§ÛŒ {symbol} ({signal_type})")

        df_15m = await get_ohlcv_cached(exchange, symbol, "15m")
        if df_15m is None or len(df_15m) < 20:
            log_rejection("insufficient_data_15m", {"length": len(df_15m) if df_15m is not None else 0})
            return None

        df_15m = compute_indicators(df_15m)
        last = df_15m.iloc[-1].to_dict()
        prev = df_15m.iloc[-2].to_dict() if len(df_15m) > 1 else None

        live_price = await get_live_price(exchange, symbol)
        if live_price is None:
            log_rejection("live_price_missing")
            return None

        atr = df_15m["ATR"].iloc[-1]
        price_diff = abs(live_price - last["close"])
        if price_diff > atr * 0.8:
            log_rejection("price_mismatch", {
                "live_price": live_price,
                "candle_price": last["close"],
                "ATR": atr,
                "diff": price_diff
            })
            return None

        volume_mean = df_15m["volume"].rolling(20).mean().iloc[-1]
        atr_mean = df_15m["ATR"].rolling(20).mean().iloc[-1]
        volume_ok = last["volume"] > volume_mean * 0.2 or atr > atr_mean * 1.2
        if not volume_ok:
            log_rejection("low_volume_or_atr", {
                "current_volume": last["volume"],
                "volume_threshold": volume_mean * 0.2,
                "atr": atr,
                "atr_threshold": atr_mean * 1.2
            })
            return None

        pattern_score = 0
        if last.get("Engulfing"): pattern_score += 1
        if last.get("Hammer"): pattern_score += 1
        if last.get("Doji"): pattern_score += 0.5
        if last.get("PinBar"): pattern_score += 1

        if confirm_next_candle and prev:
            if signal_type == "Long" and prev["close"] > prev["open"]: pattern_score += 0.5
            if signal_type == "Short" and prev["close"] < prev["open"]: pattern_score += 0.5

        log_debug(f"ğŸ“Š Ø§Ù…ØªÛŒØ§Ø² Ø§Ù„Ú¯ÙˆÙ‡Ø§ Ø¨Ø±Ø§ÛŒ {symbol}: {pattern_score:.1f}")
        if pattern_score < 1.5:
            log_rejection("weak_pattern", {
                "pattern_score": pattern_score,
                "min_required": 1.5
            })
            return None

        df_1h = await get_ohlcv_cached(exchange, symbol, "1h")
        if df_1h is None or len(df_1h) == 0:
            log_rejection("missing_data_1h")
            return None
        # ğŸ”’ Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø¹ØªØ¨Ø§Ø± Ø­Ù…Ø§ÛŒØª Ùˆ Ù…Ù‚Ø§ÙˆÙ…Øª
        if support is None or resistance is None or support <= 0 or resistance <= 0:
            log_rejection("invalid_support_resistance", {
                "support": support,
                "resistance": resistance
            })
            return None

        recent_close_1h = df_1h["close"].iloc[-1]
        if signal_type == "Long" and recent_close_1h < support * 0.95:
            log_rejection("support_broken", {
                "recent_close": recent_close_1h,
                "support": support
            })
            return None
        if signal_type == "Short" and recent_close_1h > resistance * 1.05:
            log_rejection("resistance_broken", {
                "recent_close": recent_close_1h,
                "resistance": resistance
            })
            return None

        close = last["close"]
        entry_price = live_price
        rr_factor = 2.5 if pattern_score >= 2 else 2.0
        sl_factor = 0.75

        if signal_type == "Long":
            if not (support < close < resistance and volume_ok):
                log_rejection("long_not_in_range", {
                    "close": close,
                    "support": support,
                    "resistance": resistance
                })
                return None

            sl = entry_price - atr * sl_factor
            tp = entry_price + atr * rr_factor
            rr = (tp - entry_price) / (entry_price - sl)

        elif signal_type == "Short":
            if not (support < close < resistance and volume_ok):
                log_rejection("short_not_in_range", {
                    "close": close,
                    "support": support,
                    "resistance": resistance
                })
                return None

            sl = entry_price + atr * sl_factor
            tp = entry_price - atr * rr_factor
            rr = (entry_price - tp) / (sl - entry_price)

        else:
            log_rejection("invalid_signal_type", {"signal_type": signal_type})
            return None

        if rr < 1.3:
            log_rejection("rr_too_low", {
                "RR": rr,
                "min_required": 1.3
            })
            return None

        log_debug(f"âœ… Ø³ÛŒÚ¯Ù†Ø§Ù„ ØªØ£ÛŒÛŒØ¯ Ø´Ø¯: Entry={entry_price}, SL={sl}, TP={tp}, RR={rr:.2f}")
        return {
            "entry_price": entry_price,
            "sl": sl,
            "tp": tp
        }

    except Exception as e:
        logging.error(f"âš ï¸ Ø®Ø·Ø§ÛŒ Ø¨Ø­Ø±Ø§Ù†ÛŒ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ {symbol}: {str(e)}")
        return None

# ØªØ§Ø¨Ø¹ Ù…Ø¯ÛŒØ±ÛŒØª trailing stop
async def manage_trailing_stop(exchange: ccxt.Exchange, symbol: str, entry_price: float, sl: float, signal_type: str, trail_percentage: float = 0.5):
    logging.info(f"Ø´Ø±ÙˆØ¹ Trailing Stop Ø¨Ø±Ø§ÛŒ {symbol} Ø¨Ø§ Ù†ÙˆØ¹ Ø³ÛŒÚ¯Ù†Ø§Ù„ {signal_type}, ÙˆØ±ÙˆØ¯={entry_price}, SL Ø§ÙˆÙ„ÛŒÙ‡={sl}")
    while True:
        live_price = await get_live_price(exchange, symbol)
        if live_price is None:
            logging.warning(f"Ù‚ÛŒÙ…Øª ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯ØŒ 60 Ø«Ø§Ù†ÛŒÙ‡ ØµØ¨Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù…")
            await asyncio.sleep(60)
            continue
        if (live_price > entry_price and signal_type == "Long") or (live_price < entry_price and signal_type == "Short"):
            trail_amount = live_price * (trail_percentage / 100)
            new_sl = live_price - trail_amount if signal_type == "Long" else live_price + trail_amount
            if (signal_type == "Long" and new_sl > sl) or (signal_type == "Short" and new_sl < sl):
                sl = new_sl
                logging.info(f"Trailing Stop Ø¨Ø±Ø§ÛŒ {symbol} Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ø¯: SL={sl}, Live Price={live_price}")
        await asyncio.sleep(300)  # Ú†Ú© Ù‡Ø± 5 Ø¯Ù‚ÛŒÙ‚Ù‡

# ØªØ§Ø¨Ø¹ ØªØ£ÛŒÛŒØ¯ Ù…ÙˆÙ„ØªÛŒ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…
async def multi_timeframe_confirmation(exchange: ccxt.Exchange, symbol: str, base_tf: str) -> float:
    weights = {"1d": 0.4, "4h": 0.3, "1h": 0.2, "15m": 0.1}
    total_weight = 0
    score = 0
    for tf, weight in weights.items():
        if tf == base_tf:
            continue
        try:
            df_tf = await get_ohlcv_cached(exchange, symbol, tf)
            if df_tf is None or (len(df_tf) < 50 and tf != "1d") or (len(df_tf) < 30 and tf == "1d"):
                logging.warning(f"Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ {symbol} @ {tf} Ø¯Ø± ØªØ£ÛŒÛŒØ¯ Ù…ÙˆÙ„ØªÛŒ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…: ØªØ¹Ø¯Ø§Ø¯ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§={len(df_tf) if df_tf is not None else 0}")
                continue
            df_tf["EMA12"] = df_tf["close"].ewm(span=12).mean()
            df_tf["EMA26"] = df_tf["close"].ewm(span=26).mean()
            long_trend = df_tf["EMA12"].iloc[-1] > df_tf["EMA26"].iloc[-1]
            score += (weight * 10) if long_trend else (-weight * 5)
            total_weight += weight
        except Exception as e:
            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… {tf} Ø¨Ø±Ø§ÛŒ {symbol}: {str(e)}")
            continue
    final_score = score if total_weight > 0 else 0
    logging.info(f"Ù…ÙˆÙ„ØªÛŒ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… Ø¨Ø±Ø§ÛŒ {symbol} ØªÚ©Ù…ÛŒÙ„ Ø´Ø¯: score={final_score:.2f}, total_weight={total_weight}")
    return final_score

# ØªÙ†Ø¸ÛŒÙ… Ø³Ù…Ø§ÙØ± Ø¨Ø±Ø§ÛŒ Ú©Ù†ØªØ±Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§
semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)

# ØªØ§Ø¨Ø¹ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø§ Ú©Ø´
async def get_ohlcv_cached(exchange, symbol, tf, limit=50) -> Optional[pd.DataFrame]:
    try:
        key = f"{exchange.id}_{symbol}_{tf}"
        now = datetime.utcnow()

        if key in CACHE:
            cached_df, cached_time = CACHE[key]
            if (now - cached_time).total_seconds() < CACHE_TTL:  # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² total_seconds Ø¨Ø±Ø§ÛŒ Ù…Ù‚Ø§ÛŒØ³Ù‡ ØµØ­ÛŒØ­
                return cached_df

        # Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ Ø§Ø² ØµØ±Ø§ÙÛŒ
        raw_data = await exchange.fetch_ohlcv(symbol, timeframe=tf, limit=limit)

        if not raw_data or len(raw_data) == 0:
            logging.warning(f"Ø¯Ø§Ø¯Ù‡ OHLCV Ø¨Ø±Ø§ÛŒ {symbol} / {tf} Ø®Ø§Ù„ÛŒ ÛŒØ§ Ù†Ø§Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª")
            return None  # Ø¨Ø±Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù† None Ø¨Ù‡ Ø¬Ø§ÛŒ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ù…Ø¹ØªØ¨Ø±

        df = pd.DataFrame(raw_data, columns=["timestamp", "open", "high", "low", "close", "volume"])

        # ØªØ¨Ø¯ÛŒÙ„ ØªØ§ÛŒÙ…â€ŒØ§Ø³ØªÙ…Ù¾ Ø¨Ù‡ ÙØ±Ù…Øª Ø¯Ø±Ø³Øª
        df["timestamp"] = pd.to_datetime(df["timestamp"], unit="ms", errors="coerce")
        if df["timestamp"].isnull().all():
            logging.error(f"ØªÙ…Ø§Ù…ÛŒ ØªØ§ÛŒÙ…â€ŒØ§Ø³ØªÙ…Ù¾â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ {symbol} / {tf} Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ù‡Ø³ØªÙ†Ø¯")
            return None

        # ØªØ¨Ø¯ÛŒÙ„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ Ø¨Ù‡ Ù†ÙˆØ¹ Ø¹Ø¯Ø¯ÛŒ Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§Ù‡Ø§
        for col in ["open", "high", "low", "close", "volume"]:
            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)

        # ØªÙ†Ø¸ÛŒÙ… Ø§ÛŒÙ†Ø¯Ú©Ø³
        df.set_index("timestamp", inplace=True)

        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´
        CACHE[key] = (df, now)
        logging.info(f"Ø¯Ø§Ø¯Ù‡ OHLCV Ø¨Ø±Ø§ÛŒ {symbol} / {tf} Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø±ÛŒØ§ÙØª Ùˆ Ú©Ø´ Ø´Ø¯: ØªØ¹Ø¯Ø§Ø¯ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§={len(df)}")
        return df

    except Exception as e:
        logging.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ú¯Ø±ÙØªÙ† OHLCV Ø¨Ø±Ø§ÛŒ {symbol} / {tf}: {str(e)}")
        return None
        
# ØªØ§Ø¨Ø¹ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø­Ø¬Ù… Ù¾ÙˆØ²ÛŒØ´Ù†
def calculate_position_size(account_balance: float, risk_percentage: float, entry: float, stop_loss: float) -> float:
    if entry is None or stop_loss is None or entry == 0 or stop_loss == 0:
        logging.warning(f"Ù…Ù‚Ø§Ø¯ÛŒØ± Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø­Ø¬Ù… Ù¾ÙˆØ²ÛŒØ´Ù†: entry={entry}, stop_loss={stop_loss}")
        return 0
    risk_amount = account_balance * (risk_percentage / 100)
    distance = abs(entry - stop_loss)
    position_size = risk_amount / distance if distance != 0 else 0
    return round(position_size, 2)

# ØªØ§Ø¨Ø¹ ØªØ³Øª ablation
def ablation_test(symbol_results: list, filter_name: str) -> int:
    total_signals = len([r for r in symbol_results if r is not None])
    logging.info(f"Ablation Test Ø¨Ø±Ø§ÛŒ ÙÛŒÙ„ØªØ± {filter_name}: ØªØ¹Ø¯Ø§Ø¯ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡={total_signals}")
    return total_signals

# ØªØ§Ø¨Ø¹ ØªØ­Ù„ÛŒÙ„ Ù†Ù…Ø§Ø¯
async def analyze_symbol(exchange: ccxt.Exchange, symbol: str, tf: str) -> Optional[dict]:
    global VOLUME_REJECTS, SR_REJECTS
    start_time = time.time()
    logging.info(f"Ø´Ø±ÙˆØ¹ ØªØ­Ù„ÛŒÙ„ {symbol} @ {tf}, Ø²Ù…Ø§Ù† Ø´Ø±ÙˆØ¹={datetime.now()}")

    try:
        market_structure = await analyze_market_structure(exchange, symbol)
        trend_4h = market_structure["trend"]
        trend_score_4h = market_structure["score"]
        support_4h = market_structure["support"]
        resistance_4h = market_structure["resistance"]
        fng_index = market_structure.get("fng_index", 50)

        if tf != "1h":
            logging.info(f"ØªØ­Ù„ÛŒÙ„ Ø¨Ø±Ø§ÛŒ {symbol} ÙÙ‚Ø· Ø¯Ø± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… 1h Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯. ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… ÙØ¹Ù„ÛŒ: {tf}")
            return None

        df = await get_ohlcv_cached(exchange, symbol, tf, limit=50)
        if df is None or len(df) < 30:
            logging.warning(f"Ø¯Ø§Ø¯Ù‡ Ù†Ø§Ú©Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ {symbol} @ {tf}: ØªØ¹Ø¯Ø§Ø¯ Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§={len(df) if df is not None else 0}")
            return None
        logging.info(f"Ø¯Ø§Ø¯Ù‡ Ø¯Ø±ÛŒØ§ÙØª Ø´Ø¯ Ø¨Ø±Ø§ÛŒ {symbol} @ {tf} Ø¯Ø± {time.time() - start_time:.2f} Ø«Ø§Ù†ÛŒÙ‡, ØªØ¹Ø¯Ø§Ø¯ Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§={len(df)}")

        required_columns = ['open', 'high', 'low', 'close', 'volume']
        if not all(col in df.columns for col in required_columns):
            logging.error(f"Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø² Ø¯Ø± Ø¯ÛŒØªØ§ÙØ±ÛŒÙ… {symbol} @ {tf} ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ù†Ø¯")
            return None
        df = df.ffill().bfill().fillna(0)

        df = compute_indicators(df)
        last = df.iloc[-1]

        score_long = 0
        score_short = 0
        score_log = {"long": {}, "short": {}}

        # ØªØ£ÛŒÛŒØ¯ Ø±ÙˆÙ†Ø¯ Ø¨Ø§ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… Ø¨Ø§Ù„Ø§ØªØ± (1d)
        df_1d = await get_ohlcv_cached(exchange, symbol, "1d")
        trend_1d_score = 0
        if df_1d is not None and len(df_1d) > 0:
            df_1d = compute_indicators(df_1d)
            long_trend_1d = df_1d["EMA12"].iloc[-1] > df_1d["EMA26"].iloc[-1]
            trend_1d_score = 10 if long_trend_1d else -10
            logging.info(f"ØªØ£ÛŒÛŒØ¯ Ø±ÙˆÙ†Ø¯ 1d Ø¨Ø±Ø§ÛŒ {symbol}: trend_score={trend_1d_score}")

        vol_avg = df["volume"].rolling(VOLUME_WINDOW).mean().iloc[-1]
        current_vol = df["volume"].iloc[-1]
        vol_mean = df["volume"].rolling(20).mean().iloc[-1]
        vol_std = df["volume"].rolling(20).std().iloc[-1]
        vol_threshold = vol_mean * 0.3
        vol_score = 10 if current_vol >= vol_threshold else -2
        score_long += vol_score
        score_short += vol_score
        score_log["long"]["volume"] = vol_score
        score_log["short"]["volume"] = vol_score
        logging.info(f"Ø­Ø¬Ù… Ø¨Ø±Ø§ÛŒ {symbol} @ {tf}: current_vol={current_vol:.2f}, threshold={vol_threshold:.2f}, score={vol_score}")
        if current_vol < vol_threshold:
            VOLUME_REJECTS += 1

        # Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ dynamic_rr
        atr_1h = df["ATR"].iloc[-1]
        risk_buffer = atr_1h * 2
        dynamic_rr = 2.0  # Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶
        logging.info(f"Ù†Ø³Ø¨Øª RR Ù¾ÛŒØ´â€ŒÙØ±Ø¶ Ø¨Ø±Ø§ÛŒ {symbol}: RR={dynamic_rr}")

        volatility = df["ATR"].iloc[-1] / last["close"]
        vola_mean = (df["ATR"] / df["close"]).rolling(20).mean().iloc[-1]
        vola_std = (df["ATR"] / df["close"]).rolling(20).std().iloc[-1]
        vola_threshold = vola_mean + vola_std
        vola_score = 10 if volatility > vola_threshold else -5
        score_long += vola_score
        score_short += vola_score
        score_log["long"]["volatility"] = vola_score
        score_log["short"]["volatility"] = vola_score

        adx_mean = df["ADX"].rolling(20).mean().iloc[-1]
        adx_std = df["ADX"].rolling(20).std().iloc[-1]
        adx_threshold = adx_mean + adx_std
        adx_score = 15 if last["ADX"] >= adx_threshold else -5
        trend_score = 10 if last["ADX"] >= adx_threshold * 1.5 else 0
        score_long += adx_score + trend_score
        score_short += adx_score + trend_score
        score_log["long"]["adx"] = adx_score
        score_log["short"]["adx"] = adx_score
        score_log["long"]["trend"] = trend_score
        score_log["short"]["trend"] = trend_score

        long_trend = df["EMA12"].iloc[-1] > df["EMA26"].iloc[-1]
        short_trend = not long_trend
        trend_score = 10 if long_trend else -5
        score_long += trend_score
        score_short += -trend_score
        score_log["long"]["trend_direction"] = trend_score
        score_log["short"]["trend_direction"] = -trend_score

        mtf_score = await multi_timeframe_confirmation(exchange, symbol, tf)
        score_long += mtf_score
        score_short += -mtf_score
        score_log["long"]["multi_timeframe"] = mtf_score
        score_log["short"]["multi_timeframe"] = -mtf_score

        support, resistance, vol_levels = PatternDetector.detect_support_resistance(df)
        s_r_buffer = (df["ATR"].iloc[-1] / last["close"]) * 2
        distance_to_resistance = abs(last["close"] - resistance) / last["close"]
        distance_to_support = abs(last["close"] - support) / last["close"]
        sr_score_long = 10 if distance_to_resistance > s_r_buffer else -5
        sr_score_short = 10 if distance_to_support > s_r_buffer else -5
        score_long += sr_score_long
        score_short += sr_score_short
        score_log["long"]["support_resistance"] = sr_score_long
        score_log["short"]["support_resistance"] = sr_score_short
        if distance_to_resistance <= s_r_buffer:
            SR_REJECTS += 1
        if distance_to_support <= s_r_buffer:
            SR_REJECTS += 1

        spread, liquidity_score = await check_liquidity(exchange, symbol, df)
        if spread == float('inf'):
            spread = 0.0
        score_long += liquidity_score
        score_short += liquidity_score
        score_log["long"]["liquidity"] = liquidity_score
        score_log["short"]["liquidity"] = liquidity_score
        if liquidity_score < 0:
            logging.warning(f"Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø±Ø§ÛŒ {symbol} Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ù†Ù‚Ø¯ÛŒÙ†Ú¯ÛŒ Ø¶Ø¹ÛŒÙ Ø±Ø¯ Ø´Ø¯: liquidity_score={liquidity_score}")
            return None

        fundamental_score = check_market_events(symbol)
        score_long += fundamental_score
        score_short += fundamental_score
        score_log["long"]["fundamental"] = fundamental_score
        score_log["short"]["fundamental"] = fundamental_score

        psych_long = "Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´" if last["RSI"] < 40 else "Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯" if last["RSI"] > 60 else "Ù…ØªØ¹Ø§Ø¯Ù„"
        psych_short = "Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯" if last["RSI"] > 60 else "Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´" if last["RSI"] < 40 else "Ù…ØªØ¹Ø§Ø¯Ù„"
        psych_score_long = 10 if psych_long == "Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´" else -10 if psych_long == "Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯" else 0
        psych_score_short = 10 if psych_short == "Ø§Ø´Ø¨Ø§Ø¹ Ø®Ø±ÛŒØ¯" else -10 if psych_short == "Ø§Ø´Ø¨Ø§Ø¹ ÙØ±ÙˆØ´" else 0
        score_long += psych_score_long
        score_short += psych_score_short
        score_log["long"]["psychology"] = psych_score_long
        score_log["short"]["psychology"] = psych_score_short

        bullish_rsi_div, bearish_rsi_div = PatternDetector.detect_rsi_divergence(df)
        div_score_long = 10 if bullish_rsi_div else 0
        div_score_short = 10 if bearish_rsi_div else 0
        score_long += div_score_long
        score_short += div_score_short
        score_log["long"]["rsi_divergence"] = div_score_long
        score_log["short"]["rsi_divergence"] = div_score_short

        support_buffer = (df["ATR"].iloc[-1] / last["close"]) * 1.5
        resistance_buffer = (df["ATR"].iloc[-1] / last["close"] * 1.5)
        min_conditions = 2
        conds_long = {
            "PinBar": last["PinBar"],
            "Engulfing": last["Engulfing"] and last["close"] > last["open"] and (df["volume"].iloc[-1] > df["volume"].rolling(20).mean().iloc[-1] * 1.5),
            "Elliott_Wave": df["WaveTrend"].iloc[-1] == "Up",
            "EMA_Cross": df["EMA12"].iloc[-1] > df["EMA26"].iloc[-1] and (df["volume"].iloc[-1] > df["volume"].rolling(20).mean().iloc[-1] * 1.2),
            "MACD_Cross": df["MACD"].iloc[-2] < df["Signal"].iloc[-2] and df["MACD"].iloc[-1] > df["Signal"].iloc[-1] and (df["MACD"].iloc[-1] > 0),
            "RSI_Oversold": last["RSI"] < 25,
            "Stochastic_Oversold": last["Stochastic"] < 15,
            "BB_Breakout": last["close"] > last["BB_upper"] and (df["volume"].iloc[-1] > df["volume"].rolling(20).mean().iloc[-1] * 1.5),
            "MFI_Oversold": last["MFI"] < 15,
            "ADX_Strong": last["ADX"] > 25,
            "Support_Confirmation": distance_to_support <= support_buffer and (last["PinBar"] or last["Engulfing"])
        }
        conds_short = {
            "PinBar": last["PinBar"],
            "Engulfing": last["Engulfing"] and last["close"] < last["open"] and (df["volume"].iloc[-1] > df["volume"].rolling(20).mean().iloc[-1] * 1.5),
            "Elliott_Wave": df["WaveTrend"].iloc[-1] == "Down",
            "EMA_Cross": df["EMA12"].iloc[-1] < df["EMA26"].iloc[-1] and (df["volume"].iloc[-1] > df["volume"].rolling(20).mean().iloc[-1] * 1.2),
            "MACD_Cross": df["MACD"].iloc[-2] > df["Signal"].iloc[-2] and df["MACD"].iloc[-1] < df["Signal"].iloc[-1] and (df["MACD"].iloc[-1] < 0),
            "RSI_Overbought": last["RSI"] > 75,
            "Stochastic_Overbought": last["Stochastic"] > 85,
            "BB_Breakout": last["close"] < last["BB_lower"] and (df["volume"].iloc[-1] > df["volume"].rolling(20).mean().iloc[-1] * 1.5),
            "MFI_Overbought": last["MFI"] > 85,
            "ADX_Strong": last["ADX"] > 25,
            "Resistance_Confirmation": distance_to_resistance <= resistance_buffer and (last["PinBar"] or last["Engulfing"])
        }
        indicator_score_long = (10 if conds_long["PinBar"] else 0) + \
                              (10 if conds_long["Engulfing"] else 0) + \
                              (15 if conds_long["Elliott_Wave"] else 0) + \
                              (5 if conds_long["EMA_Cross"] else 0) + \
                              (5 if conds_long["MACD_Cross"] else 0) + \
                              (3 if conds_long["RSI_Oversold"] else 0) + \
                              (3 if conds_long["Stochastic_Oversold"] else 0) + \
                              (5 if conds_long["BB_Breakout"] else 0) + \
                              (3 if conds_long["MFI_Oversold"] else 0) + \
                              (5 if conds_long["ADX_Strong"] else 0) + \
                              (10 if conds_long["Support_Confirmation"] else 0)
        indicator_score_short = (10 if conds_short["PinBar"] else 0) + \
                               (10 if conds_short["Engulfing"] else 0) + \
                               (15 if conds_short["Elliott_Wave"] else 0) + \
                               (5 if conds_short["EMA_Cross"] else 0) + \
                               (5 if conds_short["MACD_Cross"] else 0) + \
                               (3 if conds_short["RSI_Overbought"] else 0) + \
                               (3 if conds_short["Stochastic_Overbought"] else 0) + \
                               (5 if conds_short["BB_Breakout"] else 0) + \
                               (3 if conds_short["MFI_Overbought"] else 0) + \
                               (5 if conds_short["ADX_Strong"] else 0) + \
                               (10 if conds_short["Resistance_Confirmation"] else 0)

        if sum(1 for v in conds_long.values() if v) < min_conditions:
            indicator_score_long = 0
        if sum(1 for v in conds_short.values() if v) < min_conditions:
            indicator_score_short = 0

        score_long += indicator_score_long
        score_short += indicator_score_short
        score_log["long"]["indicators"] = indicator_score_long
        score_log["short"]["indicators"] = indicator_score_short
        logging.debug(f"Ø´Ø±Ø§ÛŒØ· Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ {symbol} @ {tf}: long_score={indicator_score_long}, short_score={indicator_score_short}, conditions_long={conds_long}")

        score_long += trend_score_4h
        score_short += -trend_score_4h
        score_log["long"]["market_structure_4h"] = trend_score_4h
        score_log["short"]["market_structure_4h"] = -trend_score_4h
        logging.info(f"Ø§Ù…ØªÛŒØ§Ø² Ø³Ø§Ø®ØªØ§Ø± Ø¨Ø§Ø²Ø§Ø± 4h Ø¨Ø±Ø§ÛŒ {symbol}: Long={trend_score_4h}, Short={-trend_score_4h}")

        logging.debug(f"Ø´Ø±ÙˆØ¹ ÙÛŒÙ„ØªØ± Decision Tree Ø¨Ø±Ø§ÛŒ {symbol} @ {tf}")
        signal_filter = SignalFilter()
        X_train = np.array([
            [30, 25, 2, 0.01, 0.05, 0.05, 0.01, 10, -10],
            [70, 20, 1, 0.02, 0.03, 0.03, 0.02, -10, 10],
            [50, 30, 1.5, 0.01, 0.04, 0.04, 0.01, 0, 0],
        ])
        y_train = np.array([1, 0, 1])
        signal_filter.train(X_train, y_train)
        features = [
            last["RSI"],
            last["ADX"],
            current_vol / vol_avg if vol_avg != 0 else 0,
            volatility,
            distance_to_resistance,
            distance_to_support,
            spread if 'spread' in locals() else 0.0,
            psych_score_long,
            psych_score_short
        ]
        dt_score = signal_filter.predict(features)
        score_long += dt_score
        score_short += dt_score
        score_log["long"]["decision_tree"] = dt_score
        score_log["short"]["decision_tree"] = dt_score
        logging.debug(f"ÙÛŒÙ„ØªØ± Decision Tree Ø¨Ø±Ø§ÛŒ {symbol} @ {tf}: features={features}, score={dt_score:.2f}")

        logging.info(f"Ø§Ù…ØªÛŒØ§Ø² Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ø±Ø§ÛŒ {symbol} @ {tf}: score_long={score_long:.2f}, score_short={score_short:.2f}")
        logging.info(f"Ø¬Ø²Ø¦ÛŒØ§Øª Ø§Ù…ØªÛŒØ§Ø² Long: {score_log['long']}")
        logging.info(f"Ø¬Ø²Ø¦ÛŒØ§Øª Ø§Ù…ØªÛŒØ§Ø² Short: {score_log['short']}")

        THRESHOLD = 80
        if score_long >= THRESHOLD and trend_1d_score >= 0:  # Ø´Ø±Ø· Ø§Ø¬Ø¨Ø§Ø±ÛŒ Ø±ÙˆÙ†Ø¯ 1d
            signal_type = "Long"
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ RR Ø¯Ø§ÛŒÙ†Ø§Ù…ÛŒÚ© Ø¨Ø¹Ø¯ Ø§Ø² ØªØ¹ÛŒÛŒÙ† Ù†ÙˆØ¹ Ø³ÛŒÚ¯Ù†Ø§Ù„
            if support_4h > 0:
                dynamic_rr = max(dynamic_rr, (resistance_4h - support_4h) / risk_buffer)
            logging.info(f"Ù†Ø³Ø¨Øª RR Ø¯Ø§ÛŒÙ†Ø§Ù…ÛŒÚ© Ø¨Ø±Ø§ÛŒ {symbol} (Long): RR={dynamic_rr}")

            entry_data = await find_entry_point(exchange, symbol, signal_type, support_4h, resistance_4h)
            if entry_data is None:
                logging.info(f"Ù†Ù‚Ø·Ù‡ ÙˆØ±ÙˆØ¯ Long Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø± 15m Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
                return None

            entry = entry_data["entry_price"]
            sl = entry_data["sl"]
            tp = entry_data["tp"]

            live_price = await get_live_price(exchange, symbol)
            if live_price is None:
                logging.warning(f"Ù‚ÛŒÙ…Øª ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯ØŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø±Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯")
                return None

            price_diff = abs(entry - live_price) / live_price if live_price != 0 else float('inf')
            if price_diff > 0.01:
                logging.warning(f"Ø§Ø®ØªÙ„Ø§Ù Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯ Ø¨Ø§ Ù‚ÛŒÙ…Øª ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ø§Ø³Øª: entry={entry}, live_price={live_price}, Ø§Ø®ØªÙ„Ø§Ù={price_diff}")
                return None

            if sl >= entry or tp <= entry:
                logging.warning(f"Ø­Ø¯ Ø¶Ø±Ø± ÛŒØ§ Ù‡Ø¯Ù Ø³ÙˆØ¯ Ø¨Ø±Ø§ÛŒ {symbol} Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª: entry={entry}, sl={sl}, tp={tp}")
                return None

            if abs(entry - live_price) / live_price > 0.01:
                logging.warning(f"Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯ Ø¨Ø±Ø§ÛŒ {symbol} Ø¨Ø§ Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ Ø¨Ø§Ø²Ø§Ø± ÙØ§ØµÙ„Ù‡ Ø²ÛŒØ§Ø¯ÛŒ Ø¯Ø§Ø±Ø¯: entry={entry}, live_price={live_price}")
                return None
            if abs(sl - live_price) / live_price > 0.1:
                logging.warning(f"Ø­Ø¯ Ø¶Ø±Ø± Ø¨Ø±Ø§ÛŒ {symbol} Ø¨Ø§ Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ Ø¨Ø§Ø²Ø§Ø± ÙØ§ØµÙ„Ù‡ Ø²ÛŒØ§Ø¯ÛŒ Ø¯Ø§Ø±Ø¯: sl={sl}, live_price={live_price}")
                return None
            if abs(tp - live_price) / live_price > 0.3:
                logging.warning(f"Ù‡Ø¯Ù Ø³ÙˆØ¯ Ø¨Ø±Ø§ÛŒ {symbol} Ø¨Ø§ Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ Ø¨Ø§Ø²Ø§Ø± ÙØ§ØµÙ„Ù‡ Ø²ÛŒØ§Ø¯ÛŒ Ø¯Ø§Ø±Ø¯: tp={tp}, live_price={live_price}")
                return None

            rr = round((tp - entry) / (entry - sl), 2) if (entry - sl) != 0 else 0
            position_size = calculate_position_size(10000, 1, entry, sl)
            signal_strength = "Ù‚ÙˆÛŒ" if score_long > 90 else "Ù…ØªÙˆØ³Ø·"
            result = {
                "Ù†ÙˆØ¹ Ù…Ø¹Ø§Ù…Ù„Ù‡": "Long",
                "Ù†Ù…Ø§Ø¯": symbol,
                "ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…": tf,
                "Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯": entry,
                "Ø­Ø¯ Ø¶Ø±Ø±": sl,
                "Ù‡Ø¯Ù Ø³ÙˆØ¯": tp,
"Ø±ÛŒØ³Ú© Ø¨Ù‡ Ø±ÛŒÙˆØ§Ø±Ø¯": np.float64(rr),
                "Ø­Ø¬Ù… Ù¾ÙˆØ²ÛŒØ´Ù†": position_size,
                "Ø³Ø·Ø­ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†": min(score_long, 100),
                "Ø§Ù…ØªÛŒØ§Ø²": score_long,
                "Ù‚Ø¯Ø±Øª Ø³ÛŒÚ¯Ù†Ø§Ù„": signal_strength,
                "ØªØ­Ù„ÛŒÙ„": " | ".join([k for k, v in conds_long.items() if v]),
                "Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ": psych_long,
                "Ø±ÙˆÙ†Ø¯ Ø¨Ø§Ø²Ø§Ø±": "ØµØ¹ÙˆØ¯ÛŒ",
                "ÙØ§Ù†Ø¯Ø§Ù…Ù†ØªØ§Ù„": f"Ø§Ù…ØªÛŒØ§Ø²: {fundamental_score}",
                "Ø´Ø§Ø®Øµ ØªØ±Ø³ Ùˆ Ø·Ù…Ø¹": fng_index,
                "Ø±ÙˆÙ†Ø¯ 4h": trend_4h,
                "Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ Ø¨Ø§Ø²Ø§Ø±": live_price
            }
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªØ³Ú© trailing stop
            asyncio.create_task(manage_trailing_stop(exchange, symbol, entry, sl, signal_type))
            logging.info(f"Ø³ÛŒÚ¯Ù†Ø§Ù„ Long ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯: {result}")
            return result

        elif score_short >= THRESHOLD and trend_1d_score <= 0:  # Ø´Ø±Ø· Ø§Ø¬Ø¨Ø§Ø±ÛŒ Ø±ÙˆÙ†Ø¯ 1d
            signal_type = "Short"
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ RR Ø¯Ø§ÛŒÙ†Ø§Ù…ÛŒÚ© Ø¨Ø¹Ø¯ Ø§Ø² ØªØ¹ÛŒÛŒÙ† Ù†ÙˆØ¹ Ø³ÛŒÚ¯Ù†Ø§Ù„
            if resistance_4h > 0:
                dynamic_rr = max(dynamic_rr, (resistance_4h - support_4h) / risk_buffer)
            logging.info(f"Ù†Ø³Ø¨Øª RR Ø¯Ø§ÛŒÙ†Ø§Ù…ÛŒÚ© Ø¨Ø±Ø§ÛŒ {symbol} (Short): RR={dynamic_rr}")

            entry_data = await find_entry_point(exchange, symbol, signal_type, support_4h, resistance_4h)
            if entry_data is None:
                logging.info(f"Ù†Ù‚Ø·Ù‡ ÙˆØ±ÙˆØ¯ Short Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø± 15m Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
                return None

            entry = entry_data["entry_price"]
            sl = entry_data["sl"]
            tp = entry_data["tp"]

            live_price = await get_live_price(exchange, symbol)
            if live_price is None:
                logging.warning(f"Ù‚ÛŒÙ…Øª ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} Ø¯Ø±ÛŒØ§ÙØª Ù†Ø´Ø¯ØŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø±Ø¯ Ù…ÛŒâ€ŒØ´ÙˆØ¯")
                return None

            price_diff = abs(entry - live_price) / live_price if live_price != 0 else float('inf')
            if price_diff > 0.01:
                logging.warning(f"Ø§Ø®ØªÙ„Ø§Ù Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯ Ø¨Ø§ Ù‚ÛŒÙ…Øª ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ Ø§Ø³Øª: entry={entry}, live_price={live_price}, Ø§Ø®ØªÙ„Ø§Ù={price_diff}")
                return None

            if sl <= entry or tp >= entry:
                logging.warning(f"Ø­Ø¯ Ø¶Ø±Ø± ÛŒØ§ Ù‡Ø¯Ù Ø³ÙˆØ¯ Ø¨Ø±Ø§ÛŒ {symbol} Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª: entry={entry}, sl={sl}, tp={tp}")
                return None

            if abs(entry - live_price) / live_price > 0.01:
                logging.warning(f"Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯ Ø¨Ø±Ø§ÛŒ {symbol} Ø¨Ø§ Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ Ø¨Ø§Ø²Ø§Ø± ÙØ§ØµÙ„Ù‡ Ø²ÛŒØ§Ø¯ÛŒ Ø¯Ø§Ø±Ø¯: entry={entry}, live_price={live_price}")
                return None
            if abs(sl - live_price) / live_price > 0.1:
                logging.warning(f"Ø­Ø¯ Ø¶Ø±Ø± Ø¨Ø±Ø§ÛŒ {symbol} Ø¨Ø§ Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ Ø¨Ø§Ø²Ø§Ø± ÙØ§ØµÙ„Ù‡ Ø²ÛŒØ§Ø¯ÛŒ Ø¯Ø§Ø±Ø¯: sl={sl}, live_price={live_price}")
                return None
            if abs(tp - live_price) / live_price > 0.3:
                logging.warning(f"Ù‡Ø¯Ù Ø³ÙˆØ¯ Ø¨Ø±Ø§ÛŒ {symbol} Ø¨Ø§ Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ Ø¨Ø§Ø²Ø§Ø± ÙØ§ØµÙ„Ù‡ Ø²ÛŒØ§Ø¯ÛŒ Ø¯Ø§Ø±Ø¯: tp={tp}, live_price={live_price}")
                return None

            rr = round((entry - tp) / (sl - entry), 2) if (sl - entry) != 0 else 0
            position_size = calculate_position_size(10000, 1, entry, sl)
            signal_strength = "Ù‚ÙˆÛŒ" if score_short > 90 else "Ù…ØªÙˆØ³Ø·"
            result = {
                "Ù†ÙˆØ¹ Ù…Ø¹Ø§Ù…Ù„Ù‡": "Short",
                "Ù†Ù…Ø§Ø¯": symbol,
                "ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…": tf,
                "Ù‚ÛŒÙ…Øª ÙˆØ±ÙˆØ¯": entry,
                "Ø­Ø¯ Ø¶Ø±Ø±": sl,
                "Ù‡Ø¯Ù Ø³ÙˆØ¯": tp,
"Ø±ÛŒØ³Ú© Ø¨Ù‡ Ø±ÛŒÙˆØ§Ø±Ø¯": np.float64(rr),
                "Ø­Ø¬Ù… Ù¾ÙˆØ²ÛŒØ´Ù†": position_size,
                "Ø³Ø·Ø­ Ø§Ø·Ù…ÛŒÙ†Ø§Ù†": min(score_short, 100),
                "Ø§Ù…ØªÛŒØ§Ø²": score_short,
                "Ù‚Ø¯Ø±Øª Ø³ÛŒÚ¯Ù†Ø§Ù„": signal_strength,
                "ØªØ­Ù„ÛŒÙ„": " | ".join([k for k, v in conds_short.items() if v]),
                "Ø±ÙˆØ§Ù†Ø´Ù†Ø§Ø³ÛŒ": psych_short,
                "Ø±ÙˆÙ†Ø¯ Ø¨Ø§Ø²Ø§Ø±": "Ù†Ø²ÙˆÙ„ÛŒ",
                "ÙØ§Ù†Ø¯Ø§Ù…Ù†ØªØ§Ù„": f"Ø§Ù…ØªÛŒØ§Ø²: {fundamental_score}",
                "Ø´Ø§Ø®Øµ ØªØ±Ø³ Ùˆ Ø·Ù…Ø¹": fng_index,
                "Ø±ÙˆÙ†Ø¯ 4h": trend_4h,
                "Ù‚ÛŒÙ…Øª ÙØ¹Ù„ÛŒ Ø¨Ø§Ø²Ø§Ø±": live_price
            }
            # Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† ØªØ³Ú© trailing stop
            asyncio.create_task(manage_trailing_stop(exchange, symbol, entry, sl, signal_type))
            logging.info(f"Ø³ÛŒÚ¯Ù†Ø§Ù„ Short ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯: {result}")
            return result

        logging.info(f"Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø±Ø§ÛŒ {symbol} @ {tf} Ø±Ø¯ Ø´Ø¯")
        return None

    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± ØªØ­Ù„ÛŒÙ„ {symbol} @ {tf}: {str(e)}")
        return None

# ØªØ§Ø¨Ø¹ Ø§Ø³Ú©Ù† Ù‡Ù…Ù‡ Ù†Ù…Ø§Ø¯Ù‡Ø§
async def scan_all_crypto_symbols(on_signal=None) -> None:
    exchange = ccxt.mexc({
        'enableRateLimit': True,
        'rateLimit': 2000
    })
    try:
        logging.debug(f"Ø´Ø±ÙˆØ¹ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¨Ø§Ø²Ø§Ø±Ù‡Ø§ Ø§Ø² MEXC")
        await exchange.load_markets()
        logging.info(f"Ø¨Ø§Ø²Ø§Ø±Ù‡Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯: ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…Ø§Ø¯Ù‡Ø§={len(exchange.symbols)}")
        top_coins = get_top_500_symbols_from_cmc()
        usdt_symbols = [s for s in exchange.symbols if any(s.startswith(f"{coin}/") and s.endswith("/USDT") for coin in top_coins)]
        logging.debug(f"ÙÛŒÙ„ØªØ± Ù†Ù…Ø§Ø¯Ù‡Ø§: ØªØ¹Ø¯Ø§Ø¯ USDT symbols={len(usdt_symbols)}")
        chunk_size = 10
        total_chunks = (len(usdt_symbols) + chunk_size - 1) // chunk_size
        symbol_results = []
        for idx in range(total_chunks):
            chunk = usdt_symbols[idx*chunk_size:(idx+1)*chunk_size]
            logging.info(f"Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ù† Ø¯Ø³ØªÙ‡ {idx+1}/{total_chunks}: {chunk}")
            tasks = []
            for sym in chunk:
                tasks.append(asyncio.create_task(analyze_symbol(exchange, sym, "1h")))
            async with semaphore:
                for task in asyncio.as_completed(tasks):
                    try:
                        result = await task
                        if isinstance(result, Exception):
                            logging.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªØ³Ú©: {result}")
                            continue
                        if result and on_signal:
                            await on_signal(result)
                        symbol_results.append(result)
                    except Exception as e:
                        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ù†ØªØ¸Ø§Ø± ØªØ³Ú© Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙ‡ {idx+1}: {e}")
                        continue
            await asyncio.sleep(WAIT_BETWEEN_CHUNKS)
        ablation_test(symbol_results, "volume")
        ablation_test(symbol_results, "liquidity")
        ablation_test(symbol_results, "support_resistance")
        logging.info(f"Ø¢Ù…Ø§Ø± Ø±Ø¯ Ø´Ø¯Ù†â€ŒÙ‡Ø§: Ù†Ù‚Ø¯ÛŒÙ†Ú¯ÛŒ={LIQUIDITY_REJECTS}, Ø­Ø¬Ù…={VOLUME_REJECTS}, Ø­Ù…Ø§ÛŒØª/Ù…Ù‚Ø§ÙˆÙ…Øª={SR_REJECTS}")
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ÛŒ Ú©Ù„ÛŒ Ø¯Ø± Ø§Ø³Ú©Ù† Ù†Ù…Ø§Ø¯Ù‡Ø§: {str(e)}")
    finally:
        logging.debug(f"Ø¨Ø³ØªÙ† Ø§ØªØµØ§Ù„ Ø¨Ù‡ MEXC")
        await exchange.close()

# ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ ØªØ³Øª
async def main():
    exchange = ccxt.mexc({
        'enableRateLimit': True,
        'rateLimit': 2000
    })
    try:
        logging.debug(f"Ø´Ø±ÙˆØ¹ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¨Ø§Ø²Ø§Ø±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ ØªØ³Øª")
        await exchange.load_markets()
        logging.info(f"Ø¨Ø§Ø²Ø§Ø±Ù‡Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯ Ø¨Ø±Ø§ÛŒ ØªØ³Øª")
        test_symbols = ["ANIME/USDT", "BTC/USDT", "ETH/USDT"]
        for symbol in test_symbols:
            logging.info(f"Ø´Ø±ÙˆØ¹ ØªØ³Øª Ø¨Ø±Ø§ÛŒ {symbol}")
            result = await analyze_symbol(exchange, symbol, "1h")
            if result:
                logging.info(f"Ø³ÛŒÚ¯Ù†Ø§Ù„ ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯ Ø¨Ø±Ø§ÛŒ {symbol}: {result}")
            else:
                logging.info(f"Ù‡ÛŒÚ† Ø³ÛŒÚ¯Ù†Ø§Ù„ÛŒ Ø¨Ø±Ø§ÛŒ {symbol} ØªÙˆÙ„ÛŒØ¯ Ù†Ø´Ø¯.")
    except Exception as e:
        logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø¬Ø±Ø§ÛŒ ØªØ³Øª: {str(e)}")
    finally:
        logging.debug(f"Ø¨Ø³ØªÙ† Ø§ØªØµØ§Ù„ Ø¨Ù‡ MEXC Ù¾Ø³ Ø§Ø² ØªØ³Øª")
        await exchange.close()

# Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡
if __name__ == "__main__":
    asyncio.run(main())

# === Custom Additions for Enhanced Scoring ===

def calculate_fibonacci_levels(df, high_col="high", low_col="low"):
    max_price = df[high_col].max()
    min_price = df[low_col].min()
    diff = max_price - min_price
    levels = {
        "0.236": max_price - 0.236 * diff,
        "0.382": max_price - 0.382 * diff,
        "0.5": max_price - 0.5 * diff,
        "0.618": max_price - 0.618 * diff,
        "0.786": max_price - 0.786 * diff,
    }
    return levels

def get_usdt_dominance_score(usdt_dominance_series):
    recent = usdt_dominance_series[-1]
    previous = usdt_dominance_series[-5] if len(usdt_dominance_series) >= 5 else usdt_dominance_series[0]
    if recent < previous:
        return 5  # Bullish for crypto
    elif recent > previous:
        return -5  # Bearish for crypto
    return 0

def get_moving_average_score(df, price_col="close"):
    ma50 = df[price_col].rolling(window=50).mean()
    ma100 = df[price_col].rolling(window=100).mean()
    ma200 = df[price_col].rolling(window=200).mean()
    score = 0
    if df[price_col].iloc[-1] > ma200.iloc[-1]:
        score += 5
    else:
        score -= 5
    if ma50.iloc[-1] > ma100.iloc[-1] and ma100.iloc[-1] > ma200.iloc[-1]:
        score += 3  # Uptrend alignment
    return score

# === Pattern Detection Additions ===

def detect_head_and_shoulders(df, price_col="close"):
    data = df[price_col].values
    max_idx = argrelextrema(np.array(data), np.greater)[0]

    if len(max_idx) < 3:
        return 0

    for i in range(1, len(max_idx) - 1):
        left = data[max_idx[i - 1]]
        head = data[max_idx[i]]
        right = data[max_idx[i + 1]]

        if head > left and head > right and abs(left - right) < 0.02 * head:
            return -5
    return 0

def detect_double_top(df, price_col="close"):
    data = df[price_col].values
    max_idx = argrelextrema(np.array(data), np.greater)[0]

    if len(max_idx) < 2:
        return 0

    for i in range(len(max_idx) - 1):
        first = data[max_idx[i]]
        second = data[max_idx[i + 1]]

        if abs(first - second) < 0.02 * first:
            return -3
    return 0

def detect_double_bottom(df, price_col="close"):
    data = df[price_col].values
    min_idx = argrelextrema(np.array(data), np.less)[0]

    if len(min_idx) < 2:
        return 0

    for i in range(len(min_idx) - 1):
        first = data[min_idx[i]]
        second = data[min_idx[i + 1]]

        if abs(first - second) < 0.02 * first:
            return 3
    return 0
